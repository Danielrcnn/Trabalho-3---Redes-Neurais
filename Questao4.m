close all;
clear all;
clc;
disp('Programa MLP para XOR 2 entradas');
X = [ -1 , 1 , -1 , 1 ;-1 , -1 , 1 , 1 ];
Yd =[ -1 , 1 , 1 , -1 ];
neuronios_camada_escondida = 2;
disp('Criando a rede MLP...');
net = feedforwardnet(neuronios_camada_escondida);
disp('Configurando a rede...');
net = configure(net,X,Yd);
net.divideParam.trainRatio = 1;
net.divideParam.valRatio = 0;
net.divideParam.testRatio = 0;
net.trainFcn = 'traingd';
net.performFcn = 'mse';
net.trainParam.epochs = 500000;
net.trainParam.lr = 0.1;
net.trainParam.mc = 0;
net.trainParam.goal = 0.0001;
net.layers{1}.transferFcn = 'tansig';
net.layers{2}.transferFcn = 'tansig';
disp('Inicializando a rede neural....');
net = init(net);
disp('Treinando a rede neural...');
[net, tr] = train(net,X,Yd);
plotperform(tr);
disp('Simulando a rede neural treinada...');
Ysaida = sim(net,X);
disp('Resultado: ');
disp(Ysaida);
disp('Calculando o erro da rede neural...');
perf = perform(net,Yd,Ysaida);
disp('Erro: ');
disp(perf);
wb = getwb(net);
[b,IW,LW] = separatewb(net,wb);
b = cell2mat(b);
disp('Bias de todas camadas =');
disp(b);
Wescondida = cell2mat(IW);
disp('Pesos da camada escondida =');
disp(Wescondida);
Wsaida = cell2mat(LW);
disp('Pesos da camada de saida =');
disp(Wsaida);